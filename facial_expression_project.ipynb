{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Drive to Google Colab**"
      ],
      "metadata": {
        "id": "OYeAE-9p5p93"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0b9c4rc4VcC",
        "outputId": "865d35ab-f4a9-4e2c-e197-ffdcd2fa8c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Import all necessary Libraries**"
      ],
      "metadata": {
        "id": "WFDvf8G051V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "import keras,os\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "g0gDaEbt5FK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Give path to the zip files folder from drive,  and unzip the images and give the path**"
      ],
      "metadata": {
        "id": "-H8ynrJJ6Jfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zipfile1='/content/drive/MyDrive/Computer_vision/facial_expression.zip'\n",
        "unzipdirectory= '/content/drive/MyDrive/Computer_vision/'\n"
      ],
      "metadata": {
        "id": "P2YsnW7t6nDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zipfile1,'r') as zip_ref:\n",
        "   zip_ref.extractall(unzipdirectory)"
      ],
      "metadata": {
        "id": "siRt5eqE6nBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Read an image from train and test dataset to check the data is unzip successfully**"
      ],
      "metadata": {
        "id": "kEWk_3l8lUXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "read_image_train=cv2.imread('/content/drive/MyDrive/Computer_vision/Dataset/train/happiness/100016214.png')\n",
        "read_image_train.shape\n",
        "\n",
        "# image dimension batch size for trainig the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6lC61th6cfu",
        "outputId": "bf65af10-d9b9-48bb-cf39-e474b2fc90de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 48, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "read_image_test=cv2.imread('/content/drive/MyDrive/Computer_vision/Dataset/test/surprise/103794288.png')\n",
        "read_image_test.shape\n",
        "\n",
        "# image dimension and batch size for testing the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgMPQVi2-R7N",
        "outputId": "5687cba2-87c5-4806-a98b-d7b650b6a0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 48, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Load and preprocess the data, including data augmentation**"
      ],
      "metadata": {
        "id": "LorXqtVHnTzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your dataset directory containing images of 7 classes.\n",
        "train_data_dir = r'/content/drive/MyDrive/Computer_vision/Dataset/train/'\n",
        "\n",
        "# Image dimensions\n",
        "img_width, img_height = 48, 48\n",
        "\n",
        "# Batch size for training and validation\n",
        "batch_size = 64\n",
        "\n",
        "# Create data augmentation for training images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,          # Normalize pixel values to [0, 1]\n",
        "    shear_range=0.1,         # Shear transformations\n",
        "    rotation_range=10,       # Degree range for random rotations\n",
        "    zoom_range=0.1,          # Zoom transformations\n",
        "    width_shift_range=0.1,   # Randomly shift images horizontally by 10% of the width\n",
        "    height_shift_range=0.1,  # Randomly shift images vertically by 10% of the height\n",
        "    vertical_flip=True,      # Randomly flip images vertically\n",
        "    horizontal_flip=True,    # Randomly flip images horizontally\n",
        "    fill_mode='nearest'      # Rescale pixel values to [0, 1]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "WszRRIK6nXpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize image data generator with rescaling\n",
        "\n",
        "validation_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "7iiZRs5gtbHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentataion**"
      ],
      "metadata": {
        "id": "gwy7Ev0eE6qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess training data using the data augmentation generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Computer_vision/Dataset/train',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='categorical',\n",
        "    shuffle='True'\n",
        ")\n",
        "\n",
        "# Load and preprocess test data using the data augmentation generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Computer_vision/Dataset/test',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='categorical',\n",
        "    shuffle='True'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91-dcTQ0spJb",
        "outputId": "5c25d780-cf12-48b3-c7c6-765642b92aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 32298 images belonging to 7 classes.\n",
            "Found 3589 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Creating CNN Model Architecture**"
      ],
      "metadata": {
        "id": "w-SK4Qe9uR-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "C77W3YPbujvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional and pooling layers\n",
        "model.add(layers.Conv2D(32, (3, 3),padding='valid', activation='relu', input_shape=(img_width, img_height, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='valid',activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='valid',activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# Flatten the 3D feature maps to 1D\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dense layers\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(7, activation='softmax'))  # 7 output classes\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFRiFrx5uxn8",
        "outputId": "aaf0e631-56b1-441d-8a9c-c72d0fccba92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 46, 46, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 23, 23, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 21, 21, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 7175      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,198,151\n",
            "Trainable params: 2,198,087\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for valid padding**\n",
        "Total params: 233,735\n",
        "Trainable params: 233,671\n",
        "Non-trainable params: 64"
      ],
      "metadata": {
        "id": "jc44Wq9Sxadf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for same padding**\n",
        "Total params: 397,575\n",
        "Trainable params: 397,511\n",
        "Non-trainable params: 64"
      ],
      "metadata": {
        "id": "6eKm8iZWx8Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step: 7 compile the model**"
      ],
      "metadata": {
        "id": "4Y6VvL7gw6i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aL6fKqmQw55m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Train the Model**"
      ],
      "metadata": {
        "id": "-x2QV0pOLBL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine import sequential\n",
        "# Number of training samples and steps per epoch\n",
        "num_train_samples = len(train_generator.filenames)\n",
        "steps_per_epoch = num_train_samples // batch_size     #32298 // 64\n",
        "\n",
        "# Number of epochs for training\n",
        "epochs = 50\n",
        "\n",
        "# Train the model\n",
        "train_model = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfi6iCTpxFOR",
        "outputId": "3256cbb5-a4d3-4cd6-e05c-0697ad52e63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "407/504 [=======================>......] - ETA: 33:58 - loss: 1.8126 - accuracy: 0.2472"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10: Save the Model**"
      ],
      "metadata": {
        "id": "v2KQIGXqCuew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_loss, test_acc =model.evaluate(validation_generator, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "model.save('emotion_detection_model_50epochs.h5')\n"
      ],
      "metadata": {
        "id": "PHV_-z8tBvk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 11: Plot the training and validation accuracy and loss at each epoch**"
      ],
      "metadata": {
        "id": "92ymT_aCLQFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model = train_model"
      ],
      "metadata": {
        "id": "i6ZKoLh0CLNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = emotion_model.history['loss']\n",
        "val_loss = emotion_model.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = emotion_model.history['accuracy']\n",
        "#acc = history.history['accuracy']\n",
        "val_acc = emotion_model.history['val_accuracy']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x_38s13rB3mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "my_model = load_model('emotion_detection_model_50epochs.h5', compile=False)\n",
        "\n",
        "#Generate a batch of images\n",
        "test_img, test_lbl = validation_generator.__next__()\n",
        "predictions=my_model.predict(test_img)\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "test_labels = np.argmax(test_lbl, axis=1)"
      ],
      "metadata": {
        "id": "wBIDpo2YL2oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import random\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, predictions))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "#print(cm)\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True)\n",
        "\n",
        "class_labels=['Angry','Disgust', 'Fear', 'Happy','Neutral','Sad','Surprise']\n",
        "#Check results on a few select images\n",
        "n=random.randint(0, test_img.shape[1] - 1)\n",
        "image = test_img[n]\n",
        "orig_labl = class_labels[test_labels[n]]\n",
        "pred_labl = class_labels[predictions[n]]\n",
        "plt.imshow(image[:,:,0], cmap='gray')\n",
        "plt.title(\"Original label is:\"+orig_labl+\" Predicted is: \"+ pred_labl)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CDEEGOSSMBNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save in a jason file**"
      ],
      "metadata": {
        "id": "qH8kXr95MQfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#save in a jason file\n",
        "model_json=EmotionModel.to_json()\n",
        "with open(\"emotion_model.json\",\"w\")as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "metadata": {
        "id": "pKIg31KFMPtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#now saving trained model weights**"
      ],
      "metadata": {
        "id": "7d8dITsvMXg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "EmotionModel.save_weights('emotion_model.h5')\n",
        ""
      ],
      "metadata": {
        "id": "TL3u3IctMVnu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}